environment: 
YAML: configs/scalre.yaml
==> SEED: 42
==> train_algo: scalre
==> dataset: {'cifar10': {'num_classes': 10, 'params': {'data_dir': 'datasets/cifar10', 'batch_size': 512, 'num_workers': 1, 'image_size': 32, 'algo': 'scalre'}}, 'cifar100': {'num_classes': 100, 'params': {'data_dir': 'datasets/cifar100', 'batch_size': 512, 'num_workers': 1, 'image_size': 32, 'algo': 'scalre'}}, 'timg': {'num_classes': 200, 'params': {'data_dir': 'datasets/tinyimagenet/tiny-imagenet-200', 'batch_size': 512, 'num_workers': 1, 'image_size': 64, 'algo': 'scalre'}}}
==> return_logs: False
==> eval_every: 10
==> n_epochs: 800
==> n_epochs_mlp: 100
==> gpu_id: 0
==> opt: SGD
==> opt_params: {'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0001}
==> schedular_params: {'T_max': 800, 'eta_min': 0.001}
==> mlp_opt: SGD
==> mlp_opt_params: {'lr': 0.01, 'momentum': 0.9, 'nesterov': True}
==> energy_model_params: {'eta': 0.01, 'steps': 5, 'sigma': 0.2, 'delta': 0.1, 'net_type': 'energy'}
==> energy_opt: AdamW
==> energy_model_opt_params: {'lr': 0.001}
==> model_params: {'model_name': 'resnet18', 'pretrained': False, 'proj_dim': 128, 'algo_type': 'scalre'}
==> mlp_type: hidden
==> loss: scalre
==> loss_params: {'sim': 'cosine', 'tau': 0.5}
==> distributed: False
==> model_save_path: saved_models/scalre.en.timg.r18.pth
==> warmup_epochs: 0
==> config: configs/scalre.yaml
--------------------------------------------------
Network(
  (base_encoder): BaseEncoder(
    (feat_extractor): Sequential(
      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (proj): BYOL_mlp(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=512, out_features=128, bias=True)
    )
  )
)
NOC: 200
using optimizer: SGD
loss function: scalre
loss: SimCLR(
  (supcon): SupConLoss()
)
augmentation for scalre: 
Compose(
    RandomResizedCrop(size=(64, 64), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1))
)
    RandomGrayscale(p=0.2)
    <src.data.Solarization object at 0x7d2649ec4e50>
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
Compose(
    RandomResizedCrop(size=(64, 64), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1))
)
    RandomGrayscale(p=0.2)
    <src.data.Solarization object at 0x7d2649ec4ee0>
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
# of Training Images: 100000
# of Testing Images: 10000
using optimizer: AdamW
### ScAlRe Training begins
[GPU0] epochs: [1/800] train_loss_con: 6.222 energy_loss: 250.866
[GPU0] epochs: [2/800] train_loss_con: 5.885 energy_loss: 253.619
[GPU0] epochs: [3/800] train_loss_con: 5.789 energy_loss: 255.116
[GPU0] epochs: [4/800] train_loss_con: 5.737 energy_loss: 255.975
[GPU0] epochs: [5/800] train_loss_con: 5.705 energy_loss: 255.871
[GPU0] epochs: [6/800] train_loss_con: 5.682 energy_loss: 251.048
[GPU0] epochs: [7/800] train_loss_con: 5.667 energy_loss: 236.438
[GPU0] epochs: [8/800] train_loss_con: 5.656 energy_loss: 213.409
[GPU0] epochs: [9/800] train_loss_con: 5.649 energy_loss: 188.456
[GPU0] epochs: [10/800] train_loss_con: 5.639 energy_loss: 166.653
[GPU0] epochs: [11/800] train_loss_con: 5.635 energy_loss: 110.987
[GPU0] epochs: [12/800] train_loss_con: 5.630 energy_loss: 82.435
[GPU0] epochs: [13/800] train_loss_con: 5.626 energy_loss: 59.933
[GPU0] epochs: [14/800] train_loss_con: 5.623 energy_loss: 42.700
[GPU0] epochs: [15/800] train_loss_con: 5.618 energy_loss: 32.816
[GPU0] epochs: [16/800] train_loss_con: 5.617 energy_loss: 27.174
[GPU0] epochs: [17/800] train_loss_con: 5.615 energy_loss: 23.167
[GPU0] epochs: [18/800] train_loss_con: 5.610 energy_loss: 20.748
[GPU0] epochs: [19/800] train_loss_con: 5.613 energy_loss: 17.986
[GPU0] epochs: [20/800] train_loss_con: 5.608 energy_loss: 16.406
[GPU0] epochs: [21/800] train_loss_con: 5.606 energy_loss: 15.103
[GPU0] epochs: [22/800] train_loss_con: 5.605 energy_loss: 13.668
[GPU0] epochs: [23/800] train_loss_con: 5.603 energy_loss: 12.487
[GPU0] epochs: [24/800] train_loss_con: 5.604 energy_loss: 11.343
[GPU0] epochs: [25/800] train_loss_con: 5.598 energy_loss: 10.796
[GPU0] epochs: [26/800] train_loss_con: 5.598 energy_loss: 10.372
[GPU0] epochs: [27/800] train_loss_con: 5.596 energy_loss: 10.054
[GPU0] epochs: [28/800] train_loss_con: 5.598 energy_loss: 9.782
[GPU0] epochs: [29/800] train_loss_con: 5.595 energy_loss: 9.696
[GPU0] epochs: [30/800] train_loss_con: 5.593 energy_loss: 9.487
[GPU0] epochs: [31/800] train_loss_con: 5.593 energy_loss: 9.336
[GPU0] epochs: [32/800] train_loss_con: 5.589 energy_loss: 9.251
[GPU0] epochs: [33/800] train_loss_con: 5.591 energy_loss: 9.197
[GPU0] epochs: [34/800] train_loss_con: 5.588 energy_loss: 9.067
[GPU0] epochs: [35/800] train_loss_con: 5.589 energy_loss: 9.072
[GPU0] epochs: [36/800] train_loss_con: 5.584 energy_loss: 8.814
[GPU0] epochs: [37/800] train_loss_con: 5.586 energy_loss: 8.802
[GPU0] epochs: [38/800] train_loss_con: 5.587 energy_loss: 8.698
[GPU0] epochs: [39/800] train_loss_con: 5.583 energy_loss: 8.555
[GPU0] epochs: [40/800] train_loss_con: 5.582 energy_loss: 8.483
[GPU0] epochs: [41/800] train_loss_con: 5.584 energy_loss: 8.356
[GPU0] epochs: [42/800] train_loss_con: 5.581 energy_loss: 8.202
[GPU0] epochs: [43/800] train_loss_con: 5.578 energy_loss: 8.238
[GPU0] epochs: [44/800] train_loss_con: 5.580 energy_loss: 8.050
[GPU0] epochs: [45/800] train_loss_con: 5.580 energy_loss: 8.063
[GPU0] epochs: [46/800] train_loss_con: 5.578 energy_loss: 7.975
[GPU0] epochs: [47/800] train_loss_con: 5.577 energy_loss: 7.937
[GPU0] epochs: [48/800] train_loss_con: 5.578 energy_loss: 7.765
[GPU0] epochs: [49/800] train_loss_con: 5.573 energy_loss: 7.691
[GPU0] epochs: [50/800] train_loss_con: 5.577 energy_loss: 7.583
[GPU0] epochs: [51/800] train_loss_con: 5.574 energy_loss: 7.607
[GPU0] epochs: [52/800] train_loss_con: 5.575 energy_loss: 7.607
