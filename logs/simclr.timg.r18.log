environment: 
YAML: configs/simclr.yaml
==> SEED: 42
==> train_algo: simclr
==> dataset: {'cifar10': {'num_classes': 10, 'params': {'data_dir': 'datasets/cifar10', 'batch_size': 512, 'num_workers': 1, 'image_size': 32, 'algo': 'simclr'}}, 'cifar100': {'num_classes': 100, 'params': {'data_dir': 'datasets/cifar100', 'batch_size': 512, 'num_workers': 1, 'image_size': 32, 'algo': 'simclr'}}, 'timg': {'num_classes': 200, 'params': {'data_dir': 'datasets/tinyimagenet/tiny-imagenet-200', 'batch_size': 512, 'num_workers': 1, 'image_size': 64, 'algo': 'simclr'}}}
==> return_logs: False
==> eval_every: 10
==> n_epochs: 800
==> n_epochs_mlp: 100
==> gpu_id: 0
==> opt: SGD
==> opt_params: {'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0001}
==> schedular_params: {'T_max': 800, 'eta_min': 0.001}
==> mlp_opt: SGD
==> mlp_opt_params: {'lr': 0.01, 'momentum': 0.9, 'nesterov': True}
==> model_params: {'model_name': 'resnet18', 'pretrained': False, 'proj_dim': 128, 'algo_type': 'simclr'}
==> mlp_type: hidden
==> loss: simclr
==> loss_params: {'sim': 'cosine', 'tau': 0.5}
==> distributed: False
==> model_save_path: saved_models/simclr.timg.r18.pth
==> config: configs/simclr.yaml
--------------------------------------------------
Network(
  (base_encoder): BaseEncoder(
    (feat_extractor): Sequential(
      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (proj): BYOL_mlp(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=False)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=512, out_features=128, bias=True)
    )
  )
)
NOC: 200
using optimizer: SGD
loss function: simclr
loss: SimCLR(
  (supcon): SupConLoss()
)
augmentation for simclr: 
Compose(
    RandomResizedCrop(size=(64, 64), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1))
)
    RandomGrayscale(p=0.2)
    <src.data.Solarization object at 0x779a92a105e0>
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
Compose(
    RandomResizedCrop(size=(64, 64), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1))
)
    RandomGrayscale(p=0.2)
    <src.data.Solarization object at 0x779a92a10250>
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
# of Training Images: 100000
# of Testing Images: 10000
### SimCLR Training begins
[GPU0] epochs: [1/800] train_loss_con: 6.035
[GPU0] epochs: [2/800] train_loss_con: 5.690
[GPU0] epochs: [3/800] train_loss_con: 5.599
[GPU0] epochs: [4/800] train_loss_con: 5.545
[GPU0] epochs: [5/800] train_loss_con: 5.509
[GPU0] epochs: [6/800] train_loss_con: 5.483
[GPU0] epochs: [7/800] train_loss_con: 5.468
[GPU0] epochs: [8/800] train_loss_con: 5.457
[GPU0] epochs: [9/800] train_loss_con: 5.448
[GPU0] epochs: [10/800] train_loss_con: 5.441
[GPU0] epochs: [11/800] train_loss_con: 5.438
[GPU0] epochs: [12/800] train_loss_con: 5.432
[GPU0] epochs: [13/800] train_loss_con: 5.428
[GPU0] epochs: [14/800] train_loss_con: 5.423
[GPU0] epochs: [15/800] train_loss_con: 5.420
[GPU0] epochs: [16/800] train_loss_con: 5.418
[GPU0] epochs: [17/800] train_loss_con: 5.415
[GPU0] epochs: [18/800] train_loss_con: 5.412
[GPU0] epochs: [19/800] train_loss_con: 5.412
[GPU0] epochs: [20/800] train_loss_con: 5.407
[GPU0] epochs: [21/800] train_loss_con: 5.408
[GPU0] epochs: [22/800] train_loss_con: 5.405
[GPU0] epochs: [23/800] train_loss_con: 5.405
[GPU0] epochs: [24/800] train_loss_con: 5.403
[GPU0] epochs: [25/800] train_loss_con: 5.400
[GPU0] epochs: [26/800] train_loss_con: 5.399
[GPU0] epochs: [27/800] train_loss_con: 5.397
[GPU0] epochs: [28/800] train_loss_con: 5.397
[GPU0] epochs: [29/800] train_loss_con: 5.396
[GPU0] epochs: [30/800] train_loss_con: 5.395
[GPU0] epochs: [31/800] train_loss_con: 5.393
[GPU0] epochs: [32/800] train_loss_con: 5.392
[GPU0] epochs: [33/800] train_loss_con: 5.392
[GPU0] epochs: [34/800] train_loss_con: 5.390
[GPU0] epochs: [35/800] train_loss_con: 5.388
[GPU0] epochs: [36/800] train_loss_con: 5.388
[GPU0] epochs: [37/800] train_loss_con: 5.390
[GPU0] epochs: [38/800] train_loss_con: 5.387
[GPU0] epochs: [39/800] train_loss_con: 5.385
[GPU0] epochs: [40/800] train_loss_con: 5.386
[GPU0] epochs: [41/800] train_loss_con: 5.383
[GPU0] epochs: [42/800] train_loss_con: 5.382
[GPU0] epochs: [43/800] train_loss_con: 5.381
[GPU0] epochs: [44/800] train_loss_con: 5.384
[GPU0] epochs: [45/800] train_loss_con: 5.381
[GPU0] epochs: [46/800] train_loss_con: 5.382
[GPU0] epochs: [47/800] train_loss_con: 5.384
[GPU0] epochs: [48/800] train_loss_con: 5.380
[GPU0] epochs: [49/800] train_loss_con: 5.379
[GPU0] epochs: [50/800] train_loss_con: 5.378
[GPU0] epochs: [51/800] train_loss_con: 5.377
[GPU0] epochs: [52/800] train_loss_con: 5.378
[GPU0] epochs: [53/800] train_loss_con: 5.377
